{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6a8bc4-cf7a-43ab-9e31-12cca895361c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Custom sequence SASA prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b375eec-f2f5-4bda-b53a-eb0645627b05",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f33be8-7434-4318-b47c-3fba13e09fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import sys; sys.path.append('../..')\n",
    "\n",
    "# import abnumber\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "import bin.params as p\n",
    "import bin.utils as u\n",
    "import bin.feature_generators as fg\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.PDB.PDBExceptions import PDBConstructionWarning\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deac8e40-fce4-49bc-a863-42a56c0c399e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../data/pickles/trained-test-models',)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINED_MODELS_DIR_PATH = f'{p.DATA_DIR}/pickles/trained-test-models'\n",
    "\n",
    "(TRAINED_MODELS_DIR_PATH, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a6199ae-111b-41e6-9dbe-f0c6cc73d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'randomforestN30'\n",
    "FEATURES = 'lco_cont_window_r3_all_H'\n",
    "PARAMS = {'compress': False, 'preserve_seq_ids': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d2aa19-f707-48af-8449-f580f6c4521a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lco_cont_window_r3_all_H_randomForestN30.p',\n",
       " 'lco_whole_sequence_all_H_BLmeansamerespos.p',\n",
       " 'lco_cont_window_r0_all_H_randomForestN30.p',\n",
       " 'lco_whole_sequence_all_H_BLknnwholeseqn10.p',\n",
       " 'lco_cont_window_r4_all_H_randomForestN30.p',\n",
       " 'lco_cont_window_r4_all_H_randomForestN5.p',\n",
       " 'lco_cont_window_r2_all_H_randomForestN30.p',\n",
       " 'lco_cont_window_r3_all_H_randomForestN5.p',\n",
       " 'lco_whole_sequence_all_H_BLmediansamerespos.p',\n",
       " 'lco_whole_sequence_all_H_BLavgpos.p',\n",
       " 'lco_whole_sequence_all_H_BLknnwholeseqn3.p',\n",
       " 'lco_cont_window_r1_all_H_randomForestN5.p',\n",
       " 'lco_cont_window_r2_all_H_randomForestN5.p',\n",
       " 'lco_cont_window_r1_all_H_randomForestN30.p']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# currently available (trained) models\n",
    "os.listdir(TRAINED_MODELS_DIR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ef9268-8fb9-4e93-ae74-608a1591ef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_dataset: test, metadata file path: ../../data/csv/metadata/metadata_L.csv, chains: L, shape: (643, 19)\n",
      "load_dataset: test, X file path: ../../data/csv/fasta_aligned_cleaned/fasta_aho_L.csv, chains: L, shape: (405, 154)\n",
      "load_dataset: test, Y file path: ../../data/csv/sasa_aligned/sasa_L.csv, chains: L, shape: (405, 154)\n"
     ]
    }
   ],
   "source": [
    "# load the test dataset\n",
    "X_orig, Y_orig = u.load_dataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14fc865d-7310-4447-ae14-af01f80a32e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r3_all_H_randomforestN30.p\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "model = None\n",
    "model_file_path = f'{TRAINED_MODELS_DIR_PATH}/{FEATURES}_{MODEL_NAME}.p'\n",
    "with open(model_file_path, 'rb') as trained_model_file:\n",
    "    print('model loaded from:', model_file_path)\n",
    "    model = pickle.load(trained_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5271af-79da-4041-b9fc-23a8271fb0cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define your sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b416f851-e382-4e4f-af63-6b4e46289bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bud das FASTA file\n",
    "# alebo len supnes sekvenciu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1b82d03-2740-45a8-8e63-72af36fae40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, features):\n",
    "    model_file_path = f'{TRAINED_MODELS_DIR_PATH}/{features}_{model_name}.p'\n",
    "    print('model_name:', model_name, '| features:', features)\n",
    "    print('model loaded from:', model_file_path)\n",
    "    with open(model_file_path, 'rb') as trained_model_file:\n",
    "        model = pickle.load(trained_model_file)\n",
    "        return model\n",
    "\n",
    "def save_fasta(seq_id, seq_data, seq_desc=''):\n",
    "    # Define the sequence data and identifier\n",
    "    \n",
    "    # Create a SeqRecord object\n",
    "    seq_record = SeqRecord(Seq(seq_data), id=seq_id, description=seq_desc)\n",
    "    \n",
    "    # Write the SeqRecord to a FASTA file\n",
    "    input_file_path = f\"seq_{seq_id}.fasta\"\n",
    "    SeqIO.write(seq_record, input_file_path, \"fasta\")\n",
    "    print(f\"FASTA file saved as {input_file_path}\")\n",
    "    return input_file_path\n",
    "\n",
    "def predict(fasta_path, anarci_output_path, model_name='randomforestN30', features='lco_cont_window_r3_all_H'):\n",
    "    model = get_model(model_name, features)\n",
    "    scheme = p.FINAL_NUMBERING_SCHEME\n",
    "    anarci_command = f'anarci -i {fasta_path} -o {anarci_output_path} --csv --scheme={scheme}'\n",
    "    print('ANARCI command:', anarci_command)\n",
    "    subprocess.run(anarci_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, shell=True)\n",
    "    \n",
    "    newest_file_command = \"ls -Art | tail -n 1\"\n",
    "    newest_file_command_result = subprocess.run(\n",
    "        newest_file_command, \n",
    "        stdout=subprocess.PIPE, stderr=subprocess.PIPE, \n",
    "        text=True, shell=True)\n",
    "    newest_file_command_output = newest_file_command_result.stdout.rstrip() # remove the newline from the end of the line\n",
    "    print('ROMAN newest file:', newest_file_command_output)\n",
    "    newest_file_df = pd.read_csv(newest_file_command_output, index_col=0)\n",
    "    print('newest_file_df.shape:', newest_file_df.shape)\n",
    "    \n",
    "    position_columns = u.get_position_columns(newest_file_df)\n",
    "    cols_to_remove = [c for c in newest_file_df if c not in position_columns]\n",
    "    newest_file_df = newest_file_df.drop(columns=cols_to_remove)\n",
    "    newest_file_df_ids = newest_file_df.index\n",
    "    print(newest_file_df.head(n=1))\n",
    "    \n",
    "    Xr, Yr = u.load_dataset('test_new_234', chains='H')\n",
    "    Xr.index = Xr['Id']; Xr = Xr.drop(columns=['Id'])\n",
    "    print(Xr.head(n=1))\n",
    "    \n",
    "    cols = set(Xr.columns).difference(set(newest_file_df.columns))\n",
    "    print('columns to add:', list(cols))\n",
    "    for col in cols:\n",
    "        newest_file_df[col] = '-'\n",
    "    newest_file_df = u.sort_numbering_columns(newest_file_df).reset_index() # (BLmeansaremerespos)\n",
    "    print('newest_file_df.shape:', newest_file_df.shape)\n",
    "    X_custom = newest_file_df\n",
    "    print(X_custom.head(n=1))\n",
    "    \n",
    "    # transform \n",
    "    X_custom_final, _, _ = fg.generate(X_custom, Y=None, c=None,\n",
    "                                       model_name=model_name, features=features, params=PARAMS)\n",
    "\n",
    "    last_column = X_custom_final.columns[-1]\n",
    "    print('Removing last column from X_custom_final. it probably contains IDs')\n",
    "    print(X_custom_final[last_column])\n",
    "    X_custom_final = X_custom_final.drop(columns=[last_column])\n",
    "\n",
    "    print('X_custom_final right before the prediction:', X_custom_final.head(n=1))\n",
    "    \n",
    "    predictions = model.predict(X_custom_final)\n",
    "    predictions[predictions == -1] = np.nan\n",
    "    print('len(predictions):', len(predictions))\n",
    "\n",
    "    # todo\n",
    "    if type(predictions) is np.ndarray:\n",
    "        N_SEQUENCES = X_custom.shape[0]\n",
    "        ids = list(newest_file_df_ids)\n",
    "        print('predictions type: np.ndarray | N_SEQUENCES:', N_SEQUENCES, '| len(ids):', len(ids))\n",
    "        # convert to dataframe\n",
    "        Y_pred = Yr.copy().head(newest_file_df.shape[0]).drop(columns=['Id'])\n",
    "        Y_pred.index = ids\n",
    "        #Y_pred.index = Y_orig['Id']\n",
    "        #Y_pred.drop(columns='Id', inplace=True)\n",
    "        for i, _ in tqdm(enumerate(predictions), total=len(predictions), \n",
    "                         desc='Processing individual predictions...'):\n",
    "            seq_id = ids[i % N_SEQUENCES]\n",
    "            x_index = math.floor(i / N_SEQUENCES)\n",
    "            pos_id = newest_file_df.columns[x_index+1] # starting from 1 as 0 is 'id'\n",
    "            Y_pred.loc[seq_id, pos_id] = predictions[i]\n",
    "        Y_pred = Y_pred.replace(-1, np.nan)\n",
    "        predictions = Y_pred\n",
    "    else:\n",
    "        # dataframe\n",
    "        assert isinstance(predictions, pd.DataFrame)\n",
    "        print('predictions type: pd.DataFrame')\n",
    "        assert predictions.index[0] == 0\n",
    "        predictions.index = newest_file_df_ids\n",
    "        \n",
    "    return predictions.round(2)\n",
    "\n",
    "def predict_single_sequence(seq_id, seq_data, seq_desc='', model_name='randomforestN30', features='lco_cont_window_r3_all_H'):\n",
    "    fasta_path = save_fasta(seq_id, seq_data, seq_desc)\n",
    "    anarci_output_path = f\"seq_{seq_id}_numbered\"\n",
    "    return predict(fasta_path, anarci_output_path, model_name, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "518f123c-3e89-40c9-8ad1-1d23a701b575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: BLmeansamerespos | features: lco_whole_sequence_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_whole_sequence_all_H_BLmeansamerespos.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_whole_sequence_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after non-data column drop | X.shape: (1, 164) | Y.shape: --\n",
      "[NOTE] Skipping one-hot encoding, since this is baseline model\n",
      "[FINAL] | X.shape: (1, 165) | Y.shape: --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "Name: sequence_id, dtype: object\n",
      "X_custom_final right before the prediction:    1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147 148 149\n",
      "0  -  V  Q  L  Q  E  S  -  D  A  ...   Q   G   T    -   T   L   T   V   S   S\n",
      "\n",
      "[1 rows x 164 columns]\n",
      "len(predictions): 1\n",
      "predictions type: pd.DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>143A</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roman_seq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33.06</td>\n",
       "      <td>54.88</td>\n",
       "      <td>5.95</td>\n",
       "      <td>54.57</td>\n",
       "      <td>7.57</td>\n",
       "      <td>42.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>55.04</td>\n",
       "      <td>...</td>\n",
       "      <td>61.65</td>\n",
       "      <td>19.12</td>\n",
       "      <td>8.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.87</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18.14</td>\n",
       "      <td>5.22</td>\n",
       "      <td>22.0</td>\n",
       "      <td>71.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1      2      3     4      5     6      7   8     9     10  ...  \\\n",
       "Id                                                                      ...   \n",
       "roman_seq NaN  33.06  54.88  5.95  54.57  7.57  42.21 NaN  67.0  55.04  ...   \n",
       "\n",
       "             141    142   143  143A    144  145    146   147   148    149  \n",
       "Id                                                                         \n",
       "roman_seq  61.65  19.12  8.42   NaN  40.87  3.1  18.14  5.22  22.0  71.71  \n",
       "\n",
       "[1 rows x 164 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = 'VQLQESDAELVKPGASVKISCKASGYTFTDHVIHWVKQKPEQGLEWIGYISPGNGDIKYNEKFKGKATLTADKSSSTAYMQLNSLTSEDSAVYLCKRGYYVDYWGQGTTLTVSSAKTTPPSVYPLAPSMVTLGCLVKGYFPEPVTVTWNSGSLSSGVHTFPAVLQSDLYTLSSSVTVPSSTWPSETVTCNVAHPASSTKVDKKIE'\n",
    "predict_single_sequence(\"roman_seq\", sequence, '', 'BLmeansamerespos', 'lco_whole_sequence_all_H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08e5d0a5-765f-4c7a-8f14-5db6947ced0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: BLmeansamerespos | features: lco_whole_sequence_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_whole_sequence_all_H_BLmeansamerespos.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_whole_sequence_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after non-data column drop | X.shape: (2, 164) | Y.shape: --\n",
      "[NOTE] Skipping one-hot encoding, since this is baseline model\n",
      "[FINAL] | X.shape: (2, 165) | Y.shape: --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: sequence_id, dtype: object\n",
      "X_custom_final right before the prediction:    1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147 148 149\n",
      "0  -  V  Q  L  Q  E  S  -  D  A  ...   Q   G   T    -   T   L   T   V   S   S\n",
      "\n",
      "[1 rows x 164 columns]\n",
      "len(predictions): 2\n",
      "predictions type: pd.DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>143A</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seq1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33.06</td>\n",
       "      <td>54.88</td>\n",
       "      <td>5.95</td>\n",
       "      <td>54.57</td>\n",
       "      <td>7.57</td>\n",
       "      <td>42.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>55.04</td>\n",
       "      <td>...</td>\n",
       "      <td>61.65</td>\n",
       "      <td>19.12</td>\n",
       "      <td>8.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.87</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18.14</td>\n",
       "      <td>5.22</td>\n",
       "      <td>22.0</td>\n",
       "      <td>71.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seq2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33.06</td>\n",
       "      <td>54.88</td>\n",
       "      <td>5.95</td>\n",
       "      <td>54.57</td>\n",
       "      <td>7.57</td>\n",
       "      <td>42.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>55.04</td>\n",
       "      <td>...</td>\n",
       "      <td>61.65</td>\n",
       "      <td>19.12</td>\n",
       "      <td>8.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.87</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18.14</td>\n",
       "      <td>5.22</td>\n",
       "      <td>22.0</td>\n",
       "      <td>71.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1      2      3     4      5     6      7   8     9     10  ...    141  \\\n",
       "Id                                                                 ...          \n",
       "seq1 NaN  33.06  54.88  5.95  54.57  7.57  42.21 NaN  67.0  55.04  ...  61.65   \n",
       "seq2 NaN  33.06  54.88  5.95  54.57  7.57  42.21 NaN  67.0  55.04  ...  61.65   \n",
       "\n",
       "        142   143  143A    144  145    146   147   148    149  \n",
       "Id                                                             \n",
       "seq1  19.12  8.42   NaN  40.87  3.1  18.14  5.22  22.0  71.71  \n",
       "seq2  19.12  8.42   NaN  40.87  3.1  18.14  5.22  22.0  71.71  \n",
       "\n",
       "[2 rows x 164 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"seq_seq1.fasta\", \"seq_seq1_numbered\", 'BLmeansamerespos', 'lco_whole_sequence_all_H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daa73de1-2588-4983-90e0-beef4d61d839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: randomforestN30 | features: lco_cont_window_r3_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r3_all_H_randomforestN30.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r3_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (2, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (2, 170) Y.shape --\n",
      "after window transforms: X_window.shape (328, 9) Y_window.shape --\n",
      "[FINAL] X.shape (328, 156) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "     ... \n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: 156, Length: 328, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  145  146  147  148  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   149  150  151  152  153  154  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 155 columns]\n",
      "len(predictions): 328\n",
      "predictions type: np.ndarray | N_SEQUENCES: 2 | len(ids): 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72ae1138b2942ffa5e55229da114b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>143A</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seq1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58.31</td>\n",
       "      <td>64.64</td>\n",
       "      <td>5.53</td>\n",
       "      <td>54.27</td>\n",
       "      <td>7.97</td>\n",
       "      <td>32.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.54</td>\n",
       "      <td>44.88</td>\n",
       "      <td>...</td>\n",
       "      <td>61.28</td>\n",
       "      <td>17.62</td>\n",
       "      <td>6.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.71</td>\n",
       "      <td>3.05</td>\n",
       "      <td>20.44</td>\n",
       "      <td>5.24</td>\n",
       "      <td>21.74</td>\n",
       "      <td>72.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seq2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58.31</td>\n",
       "      <td>64.64</td>\n",
       "      <td>5.53</td>\n",
       "      <td>54.27</td>\n",
       "      <td>7.97</td>\n",
       "      <td>32.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.54</td>\n",
       "      <td>44.88</td>\n",
       "      <td>...</td>\n",
       "      <td>61.28</td>\n",
       "      <td>17.62</td>\n",
       "      <td>6.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.71</td>\n",
       "      <td>3.05</td>\n",
       "      <td>20.44</td>\n",
       "      <td>5.24</td>\n",
       "      <td>21.74</td>\n",
       "      <td>72.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1      2      3     4      5     6     7   8      9     10  ...    141  \\\n",
       "seq1 NaN  58.31  64.64  5.53  54.27  7.97  32.6 NaN  65.54  44.88  ...  61.28   \n",
       "seq2 NaN  58.31  64.64  5.53  54.27  7.97  32.6 NaN  65.54  44.88  ...  61.28   \n",
       "\n",
       "        142   143  143A    144   145    146   147    148    149  \n",
       "seq1  17.62  6.69   NaN  41.71  3.05  20.44  5.24  21.74  72.09  \n",
       "seq2  17.62  6.69   NaN  41.71  3.05  20.44  5.24  21.74  72.09  \n",
       "\n",
       "[2 rows x 164 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"seq_seq1.fasta\", \"seq_seq1_numbered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84d3e612-0e00-4db6-be58-b51e740fe5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomForestN30 lco_cont_window_r3_all_H\n",
      "model_name: randomForestN30 | features: lco_cont_window_r3_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r3_all_H_randomForestN30.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r3_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (2, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (2, 170) Y.shape --\n",
      "after window transforms: X_window.shape (328, 9) Y_window.shape --\n",
      "[FINAL] X.shape (328, 156) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "     ... \n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: 156, Length: 328, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  145  146  147  148  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   149  150  151  152  153  154  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 155 columns]\n",
      "len(predictions): 328\n",
      "predictions type: np.ndarray | N_SEQUENCES: 2 | len(ids): 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7c332d319a417bab0f6fc181456975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: randomForestN30 | features: lco_cont_window_r3_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r3_all_H_randomForestN30.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r3_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (1, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (1, 170) Y.shape --\n",
      "after window transforms: X_window.shape (164, 9) Y_window.shape --\n",
      "[FINAL] X.shape (164, 156) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "       ...    \n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "Name: 156, Length: 164, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  145  146  147  148  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   149  150  151  152  153  154  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 155 columns]\n",
      "len(predictions): 164\n",
      "predictions type: np.ndarray | N_SEQUENCES: 1 | len(ids): 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc3137f56c9416d9e0886988bdb07ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLmeansamerespos lco_whole_sequence_all_H\n",
      "model_name: BLmeansamerespos | features: lco_whole_sequence_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_whole_sequence_all_H_BLmeansamerespos.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_whole_sequence_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after non-data column drop | X.shape: (2, 164) | Y.shape: --\n",
      "[NOTE] Skipping one-hot encoding, since this is baseline model\n",
      "[FINAL] | X.shape: (2, 165) | Y.shape: --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: sequence_id, dtype: object\n",
      "X_custom_final right before the prediction:    1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147 148 149\n",
      "0  -  V  Q  L  Q  E  S  -  D  A  ...   Q   G   T    -   T   L   T   V   S   S\n",
      "\n",
      "[1 rows x 164 columns]\n",
      "len(predictions): 2\n",
      "predictions type: pd.DataFrame\n",
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: BLmeansamerespos | features: lco_whole_sequence_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_whole_sequence_all_H_BLmeansamerespos.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_whole_sequence_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after non-data column drop | X.shape: (1, 164) | Y.shape: --\n",
      "[NOTE] Skipping one-hot encoding, since this is baseline model\n",
      "[FINAL] | X.shape: (1, 165) | Y.shape: --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "Name: sequence_id, dtype: object\n",
      "X_custom_final right before the prediction:    1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147 148 149\n",
      "0  -  V  Q  L  Q  E  S  -  D  A  ...   Q   G   T    -   T   L   T   V   S   S\n",
      "\n",
      "[1 rows x 164 columns]\n",
      "len(predictions): 1\n",
      "predictions type: pd.DataFrame\n",
      "randomForestN30 lco_cont_window_r0_all_H\n",
      "model_name: randomForestN30 | features: lco_cont_window_r0_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r0_all_H_randomForestN30.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r0_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (2, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (2, 164) Y.shape --\n",
      "after window transforms: X_window.shape (328, 3) Y_window.shape --\n",
      "[FINAL] X.shape (328, 24) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "     ... \n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: 24, Length: 328, dtype: object\n",
      "X_custom_final right before the prediction:    0   1   2   3   4   5   6   7   8   9   ...  13  14  15  16  17  18  19  \\\n",
      "0   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "\n",
      "   20  21   22  \n",
      "0   0   0  0.0  \n",
      "\n",
      "[1 rows x 23 columns]\n",
      "len(predictions): 328\n",
      "predictions type: np.ndarray | N_SEQUENCES: 2 | len(ids): 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fce8eecd3fc473685910c4a4137a3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: randomForestN30 | features: lco_cont_window_r0_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r0_all_H_randomForestN30.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r0_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (1, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (1, 164) Y.shape --\n",
      "after window transforms: X_window.shape (164, 3) Y_window.shape --\n",
      "[FINAL] X.shape (164, 24) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "       ...    \n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "Name: 24, Length: 164, dtype: object\n",
      "X_custom_final right before the prediction:    0   1   2   3   4   5   6   7   8   9   ...  13  14  15  16  17  18  19  \\\n",
      "0   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "\n",
      "   20  21   22  \n",
      "0   0   0  0.0  \n",
      "\n",
      "[1 rows x 23 columns]\n",
      "len(predictions): 164\n",
      "predictions type: np.ndarray | N_SEQUENCES: 1 | len(ids): 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08669dd4c795422e8596ea1b3de16622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLknnwholeseqn10 lco_whole_sequence_all_H\n",
      "model_name: BLknnwholeseqn10 | features: lco_whole_sequence_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_whole_sequence_all_H_BLknnwholeseqn10.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_whole_sequence_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after non-data column drop | X.shape: (2, 164) | Y.shape: --\n",
      "[NOTE] Skipping one-hot encoding, since this is baseline model\n",
      "[FINAL] | X.shape: (2, 165) | Y.shape: --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: sequence_id, dtype: object\n",
      "X_custom_final right before the prediction:    1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147 148 149\n",
      "0  -  V  Q  L  Q  E  S  -  D  A  ...   Q   G   T    -   T   L   T   V   S   S\n",
      "\n",
      "[1 rows x 164 columns]\n",
      "len(predictions): 2\n",
      "predictions type: pd.DataFrame\n",
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: BLknnwholeseqn10 | features: lco_whole_sequence_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_whole_sequence_all_H_BLknnwholeseqn10.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_whole_sequence_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after non-data column drop | X.shape: (1, 164) | Y.shape: --\n",
      "[NOTE] Skipping one-hot encoding, since this is baseline model\n",
      "[FINAL] | X.shape: (1, 165) | Y.shape: --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "Name: sequence_id, dtype: object\n",
      "X_custom_final right before the prediction:    1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147 148 149\n",
      "0  -  V  Q  L  Q  E  S  -  D  A  ...   Q   G   T    -   T   L   T   V   S   S\n",
      "\n",
      "[1 rows x 164 columns]\n",
      "len(predictions): 1\n",
      "predictions type: pd.DataFrame\n",
      "randomForestN30 lco_cont_window_r4_all_H\n",
      "model_name: randomForestN30 | features: lco_cont_window_r4_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r4_all_H_randomForestN30.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r4_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (2, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (2, 172) Y.shape --\n",
      "after window transforms: X_window.shape (328, 11) Y_window.shape --\n",
      "[FINAL] X.shape (328, 200) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "     ... \n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: 200, Length: 328, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  189  190  191  192  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    1    0    0   \n",
      "\n",
      "   193  194  195  196  197  198  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 199 columns]\n",
      "len(predictions): 328\n",
      "predictions type: np.ndarray | N_SEQUENCES: 2 | len(ids): 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a37f1e4b6274d25a5df02ea1586e0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: randomForestN30 | features: lco_cont_window_r4_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r4_all_H_randomForestN30.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r4_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (1, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (1, 172) Y.shape --\n",
      "after window transforms: X_window.shape (164, 11) Y_window.shape --\n",
      "[FINAL] X.shape (164, 200) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "       ...    \n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "Name: 200, Length: 164, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  189  190  191  192  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    1    0    0   \n",
      "\n",
      "   193  194  195  196  197  198  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 199 columns]\n",
      "len(predictions): 164\n",
      "predictions type: np.ndarray | N_SEQUENCES: 1 | len(ids): 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fba6a619477462793c8c9691dc540a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomForestN5 lco_cont_window_r4_all_H\n",
      "model_name: randomForestN5 | features: lco_cont_window_r4_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r4_all_H_randomForestN5.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r4_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (2, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (2, 172) Y.shape --\n",
      "after window transforms: X_window.shape (328, 11) Y_window.shape --\n",
      "[FINAL] X.shape (328, 200) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "     ... \n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: 200, Length: 328, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  189  190  191  192  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    1    0    0   \n",
      "\n",
      "   193  194  195  196  197  198  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 199 columns]\n",
      "len(predictions): 328\n",
      "predictions type: np.ndarray | N_SEQUENCES: 2 | len(ids): 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577bb7eeedcc484daea44bae0dec8c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: randomForestN5 | features: lco_cont_window_r4_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r4_all_H_randomForestN5.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r4_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (1, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (1, 172) Y.shape --\n",
      "after window transforms: X_window.shape (164, 11) Y_window.shape --\n",
      "[FINAL] X.shape (164, 200) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "       ...    \n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "Name: 200, Length: 164, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  189  190  191  192  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    1    0    0   \n",
      "\n",
      "   193  194  195  196  197  198  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 199 columns]\n",
      "len(predictions): 164\n",
      "predictions type: np.ndarray | N_SEQUENCES: 1 | len(ids): 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af21aabd35a42e3a1767c61186a3367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomForestN30 lco_cont_window_r2_all_H\n",
      "model_name: randomForestN30 | features: lco_cont_window_r2_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r2_all_H_randomForestN30.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r2_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (2, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (2, 168) Y.shape --\n",
      "after window transforms: X_window.shape (328, 7) Y_window.shape --\n",
      "[FINAL] X.shape (328, 112) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "     ... \n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: 112, Length: 328, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  101  102  103  104  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    1    0    0   \n",
      "\n",
      "   105  106  107  108  109  110  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 111 columns]\n",
      "len(predictions): 328\n",
      "predictions type: np.ndarray | N_SEQUENCES: 2 | len(ids): 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f4c07804af4cefb299b7c7866bab15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: randomForestN30 | features: lco_cont_window_r2_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r2_all_H_randomForestN30.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r2_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (1, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (1, 168) Y.shape --\n",
      "after window transforms: X_window.shape (164, 7) Y_window.shape --\n",
      "[FINAL] X.shape (164, 112) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "       ...    \n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "Name: 112, Length: 164, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  101  102  103  104  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    1    0    0   \n",
      "\n",
      "   105  106  107  108  109  110  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 111 columns]\n",
      "len(predictions): 164\n",
      "predictions type: np.ndarray | N_SEQUENCES: 1 | len(ids): 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb688c7883bb48808c60d27c26e2875c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomForestN5 lco_cont_window_r3_all_H\n",
      "model_name: randomForestN5 | features: lco_cont_window_r3_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r3_all_H_randomForestN5.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r3_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (2, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (2, 170) Y.shape --\n",
      "after window transforms: X_window.shape (328, 9) Y_window.shape --\n",
      "[FINAL] X.shape (328, 156) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "     ... \n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: 156, Length: 328, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  145  146  147  148  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   149  150  151  152  153  154  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 155 columns]\n",
      "len(predictions): 328\n",
      "predictions type: np.ndarray | N_SEQUENCES: 2 | len(ids): 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0a8678507c40f5aebcbc4352556540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: randomForestN5 | features: lco_cont_window_r3_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r3_all_H_randomForestN5.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r3_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (1, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (1, 170) Y.shape --\n",
      "after window transforms: X_window.shape (164, 9) Y_window.shape --\n",
      "[FINAL] X.shape (164, 156) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "       ...    \n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "Name: 156, Length: 164, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  145  146  147  148  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
      "\n",
      "   149  150  151  152  153  154  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 155 columns]\n",
      "len(predictions): 164\n",
      "predictions type: np.ndarray | N_SEQUENCES: 1 | len(ids): 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7afd646cb2c4de082373c2d9deaea76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLmediansamerespos lco_whole_sequence_all_H\n",
      "model_name: BLmediansamerespos | features: lco_whole_sequence_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_whole_sequence_all_H_BLmediansamerespos.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_whole_sequence_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after non-data column drop | X.shape: (2, 164) | Y.shape: --\n",
      "[NOTE] Skipping one-hot encoding, since this is baseline model\n",
      "[FINAL] | X.shape: (2, 165) | Y.shape: --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: sequence_id, dtype: object\n",
      "X_custom_final right before the prediction:    1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147 148 149\n",
      "0  -  V  Q  L  Q  E  S  -  D  A  ...   Q   G   T    -   T   L   T   V   S   S\n",
      "\n",
      "[1 rows x 164 columns]\n",
      "len(predictions): 2\n",
      "predictions type: pd.DataFrame\n",
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: BLmediansamerespos | features: lco_whole_sequence_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_whole_sequence_all_H_BLmediansamerespos.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_whole_sequence_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after non-data column drop | X.shape: (1, 164) | Y.shape: --\n",
      "[NOTE] Skipping one-hot encoding, since this is baseline model\n",
      "[FINAL] | X.shape: (1, 165) | Y.shape: --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "Name: sequence_id, dtype: object\n",
      "X_custom_final right before the prediction:    1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147 148 149\n",
      "0  -  V  Q  L  Q  E  S  -  D  A  ...   Q   G   T    -   T   L   T   V   S   S\n",
      "\n",
      "[1 rows x 164 columns]\n",
      "len(predictions): 1\n",
      "predictions type: pd.DataFrame\n",
      "BLavgpos lco_whole_sequence_all_H\n",
      "model_name: BLavgpos | features: lco_whole_sequence_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_whole_sequence_all_H_BLavgpos.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_whole_sequence_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after non-data column drop | X.shape: (2, 164) | Y.shape: --\n",
      "[NOTE] Skipping one-hot encoding, since this is baseline model\n",
      "[FINAL] | X.shape: (2, 165) | Y.shape: --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: sequence_id, dtype: object\n",
      "X_custom_final right before the prediction:    1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147 148 149\n",
      "0  -  V  Q  L  Q  E  S  -  D  A  ...   Q   G   T    -   T   L   T   V   S   S\n",
      "\n",
      "[1 rows x 164 columns]\n",
      "len(predictions): 2\n",
      "predictions type: pd.DataFrame\n",
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: BLavgpos | features: lco_whole_sequence_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_whole_sequence_all_H_BLavgpos.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_whole_sequence_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after non-data column drop | X.shape: (1, 164) | Y.shape: --\n",
      "[NOTE] Skipping one-hot encoding, since this is baseline model\n",
      "[FINAL] | X.shape: (1, 165) | Y.shape: --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "Name: sequence_id, dtype: object\n",
      "X_custom_final right before the prediction:    1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147 148 149\n",
      "0  -  V  Q  L  Q  E  S  -  D  A  ...   Q   G   T    -   T   L   T   V   S   S\n",
      "\n",
      "[1 rows x 164 columns]\n",
      "len(predictions): 1\n",
      "predictions type: pd.DataFrame\n",
      "BLknnwholeseqn3 lco_whole_sequence_all_H\n",
      "model_name: BLknnwholeseqn3 | features: lco_whole_sequence_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_whole_sequence_all_H_BLknnwholeseqn3.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_whole_sequence_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after non-data column drop | X.shape: (2, 164) | Y.shape: --\n",
      "[NOTE] Skipping one-hot encoding, since this is baseline model\n",
      "[FINAL] | X.shape: (2, 165) | Y.shape: --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: sequence_id, dtype: object\n",
      "X_custom_final right before the prediction:    1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147 148 149\n",
      "0  -  V  Q  L  Q  E  S  -  D  A  ...   Q   G   T    -   T   L   T   V   S   S\n",
      "\n",
      "[1 rows x 164 columns]\n",
      "len(predictions): 2\n",
      "predictions type: pd.DataFrame\n",
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: BLknnwholeseqn3 | features: lco_whole_sequence_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_whole_sequence_all_H_BLknnwholeseqn3.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_whole_sequence_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after non-data column drop | X.shape: (1, 164) | Y.shape: --\n",
      "[NOTE] Skipping one-hot encoding, since this is baseline model\n",
      "[FINAL] | X.shape: (1, 165) | Y.shape: --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "Name: sequence_id, dtype: object\n",
      "X_custom_final right before the prediction:    1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147 148 149\n",
      "0  -  V  Q  L  Q  E  S  -  D  A  ...   Q   G   T    -   T   L   T   V   S   S\n",
      "\n",
      "[1 rows x 164 columns]\n",
      "len(predictions): 1\n",
      "predictions type: pd.DataFrame\n",
      "randomForestN5 lco_cont_window_r1_all_H\n",
      "model_name: randomForestN5 | features: lco_cont_window_r1_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r1_all_H_randomForestN5.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r1_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (2, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (2, 166) Y.shape --\n",
      "after window transforms: X_window.shape (328, 5) Y_window.shape --\n",
      "[FINAL] X.shape (328, 68) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "     ... \n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: 68, Length: 328, dtype: object\n",
      "X_custom_final right before the prediction:    0   1   2   3   4   5   6   7   8   9   ...  57  58  59  60  61  62  63  \\\n",
      "0   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   1   \n",
      "\n",
      "   64  65   66  \n",
      "0   0   0  0.0  \n",
      "\n",
      "[1 rows x 67 columns]\n",
      "len(predictions): 328\n",
      "predictions type: np.ndarray | N_SEQUENCES: 2 | len(ids): 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ea1be8a9c34f50bc56aea22a112dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: randomForestN5 | features: lco_cont_window_r1_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r1_all_H_randomForestN5.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r1_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (1, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (1, 166) Y.shape --\n",
      "after window transforms: X_window.shape (164, 5) Y_window.shape --\n",
      "[FINAL] X.shape (164, 68) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "       ...    \n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "Name: 68, Length: 164, dtype: object\n",
      "X_custom_final right before the prediction:    0   1   2   3   4   5   6   7   8   9   ...  57  58  59  60  61  62  63  \\\n",
      "0   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   1   \n",
      "\n",
      "   64  65   66  \n",
      "0   0   0  0.0  \n",
      "\n",
      "[1 rows x 67 columns]\n",
      "len(predictions): 164\n",
      "predictions type: np.ndarray | N_SEQUENCES: 1 | len(ids): 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbab05a26b9a4f26a114e25a2eba9a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomForestN5 lco_cont_window_r2_all_H\n",
      "model_name: randomForestN5 | features: lco_cont_window_r2_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r2_all_H_randomForestN5.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r2_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (2, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (2, 168) Y.shape --\n",
      "after window transforms: X_window.shape (328, 7) Y_window.shape --\n",
      "[FINAL] X.shape (328, 112) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "     ... \n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: 112, Length: 328, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  101  102  103  104  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    1    0    0   \n",
      "\n",
      "   105  106  107  108  109  110  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 111 columns]\n",
      "len(predictions): 328\n",
      "predictions type: np.ndarray | N_SEQUENCES: 2 | len(ids): 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f79b6bd3b54e4b99fd9826d4dd2995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: randomForestN5 | features: lco_cont_window_r2_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r2_all_H_randomForestN5.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r2_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (1, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (1, 168) Y.shape --\n",
      "after window transforms: X_window.shape (164, 7) Y_window.shape --\n",
      "[FINAL] X.shape (164, 112) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "       ...    \n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "Name: 112, Length: 164, dtype: object\n",
      "X_custom_final right before the prediction:    0    1    2    3    4    5    6    7    8    9    ...  101  102  103  104  \\\n",
      "0    0    0    0    0    0    0    0    0    0    0  ...    0    1    0    0   \n",
      "\n",
      "   105  106  107  108  109  110  \n",
      "0    0    0    0    0    0  0.0  \n",
      "\n",
      "[1 rows x 111 columns]\n",
      "len(predictions): 164\n",
      "predictions type: np.ndarray | N_SEQUENCES: 1 | len(ids): 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f991b696694c7e8479af4382e8c8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomForestN30 lco_cont_window_r1_all_H\n",
      "model_name: randomForestN30 | features: lco_cont_window_r1_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r1_all_H_randomForestN30.p\n",
      "ANARCI command: anarci -i seq_seq1.fasta -o seq_seq1_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_seq1_numbered_H.csv\n",
      "newest_file_df.shape: (2, 161)\n",
      "      1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147 148  \\\n",
      "Id                                  ...                                       \n",
      "seq1  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   S   \n",
      "\n",
      "     149  \n",
      "Id        \n",
      "seq1   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (2, 165)\n",
      "     Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147 148  \\\n",
      "0  seq1  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   S   \n",
      "\n",
      "  149  \n",
      "0   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r1_all_H\n",
      "X.shape: (2, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (2, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (2, 166) Y.shape --\n",
      "after window transforms: X_window.shape (328, 5) Y_window.shape --\n",
      "[FINAL] X.shape (328, 68) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "     ... \n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "0    seq1\n",
      "1    seq2\n",
      "Name: 68, Length: 328, dtype: object\n",
      "X_custom_final right before the prediction:    0   1   2   3   4   5   6   7   8   9   ...  57  58  59  60  61  62  63  \\\n",
      "0   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   1   \n",
      "\n",
      "   64  65   66  \n",
      "0   0   0  0.0  \n",
      "\n",
      "[1 rows x 67 columns]\n",
      "len(predictions): 328\n",
      "predictions type: np.ndarray | N_SEQUENCES: 2 | len(ids): 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e8287534964be8a8d577363b81979a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASTA file saved as seq_roman_seq.fasta\n",
      "model_name: randomForestN30 | features: lco_cont_window_r1_all_H\n",
      "model loaded from: ../../data/pickles/trained-test-models/lco_cont_window_r1_all_H_randomForestN30.p\n",
      "ANARCI command: anarci -i seq_roman_seq.fasta -o seq_roman_seq_numbered --csv --scheme=aho\n",
      "ROMAN newest file: seq_roman_seq_numbered_H.csv\n",
      "newest_file_df.shape: (1, 161)\n",
      "           1  2  3  4  5  6  7  8  9 10  ... 140 141 142 143 144 145 146 147  \\\n",
      "Id                                       ...                                   \n",
      "roman_seq  -  V  Q  L  Q  E  S  -  D  A  ...   G   Q   G   T   T   L   T   V   \n",
      "\n",
      "          148 149  \n",
      "Id                 \n",
      "roman_seq   S   S  \n",
      "\n",
      "[1 rows x 149 columns]\n",
      "load_dataset: test_new_234, metadata file path: ../../data/csv/metadataJuly2024/metadata_H.csv, chains: H, shape: (888, 19)\n",
      "load_dataset: test_new_234, X file path: ../../data/csv/fasta_aligned_cleaned_dlJuly2024/fasta_aho_H.csv, chains: H, shape: (888, 165)\n",
      "load_dataset: test_new_234, Y file path: ../../data/csv/sasa_aligned_dlJuly2024/sasa_H.csv, chains: H, shape: (888, 165)\n",
      "        1  2  3  4  5  6  7  8  9 10  ... 141 142 143 143A 144 145 146 147  \\\n",
      "Id                                    ...                                    \n",
      "7DF1:H  -  V  Q  L  V  Q  S  -  G  A  ...   Q   G   T    -   M   V   T   V   \n",
      "\n",
      "       148 149  \n",
      "Id              \n",
      "7DF1:H   S   -  \n",
      "\n",
      "[1 rows x 164 columns]\n",
      "columns to add: ['85B', '85A', '85E', '85H', '85D', '123D', '85C', '85F', '63A', '63B', '85G', '123A', '123C', '123B', '143A']\n",
      "newest_file_df.shape: (1, 165)\n",
      "          Id  1  2  3  4  5  6  7  8  9  ... 141 142 143 143A 144 145 146 147  \\\n",
      "0  roman_seq  -  V  Q  L  Q  E  S  -  D  ...   Q   G   T    -   T   L   T   V   \n",
      "\n",
      "  148 149  \n",
      "0   S   S  \n",
      "\n",
      "[1 rows x 165 columns]\n",
      "lco_cont_window_r1_all_H\n",
      "X.shape: (1, 165) | Y.shape: --\n",
      "after drop_nondata_columns: X.shape (1, 164) Y.shape --\n",
      "after _add_sequence_end: X.shape (1, 166) Y.shape --\n",
      "after window transforms: X_window.shape (164, 5) Y_window.shape --\n",
      "[FINAL] X.shape (164, 68) Y.shape --\n",
      "Removing last column from X_custom_final. it probably contains IDs\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "       ...    \n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "0    roman_seq\n",
      "Name: 68, Length: 164, dtype: object\n",
      "X_custom_final right before the prediction:    0   1   2   3   4   5   6   7   8   9   ...  57  58  59  60  61  62  63  \\\n",
      "0   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   1   \n",
      "\n",
      "   64  65   66  \n",
      "0   0   0  0.0  \n",
      "\n",
      "[1 rows x 67 columns]\n",
      "len(predictions): 164\n",
      "predictions type: np.ndarray | N_SEQUENCES: 1 | len(ids): 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53d407326734f1aaa8dff11622a6c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing individual predictions...:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing - does it all run without an error?\n",
    "pipeline_names = ['lco_cont_window_r3_all_H_randomForestN30.p',\n",
    " 'lco_whole_sequence_all_H_BLmeansamerespos.p',\n",
    " 'lco_cont_window_r0_all_H_randomForestN30.p',\n",
    " 'lco_whole_sequence_all_H_BLknnwholeseqn10.p',\n",
    " 'lco_cont_window_r4_all_H_randomForestN30.p',\n",
    " 'lco_cont_window_r4_all_H_randomForestN5.p',\n",
    " 'lco_cont_window_r2_all_H_randomForestN30.p',\n",
    " 'lco_cont_window_r3_all_H_randomForestN5.p',\n",
    " 'lco_whole_sequence_all_H_BLmediansamerespos.p',\n",
    " 'lco_whole_sequence_all_H_BLavgpos.p',\n",
    " 'lco_whole_sequence_all_H_BLknnwholeseqn3.p',\n",
    " 'lco_cont_window_r1_all_H_randomForestN5.p',\n",
    " 'lco_cont_window_r2_all_H_randomForestN5.p',\n",
    " 'lco_cont_window_r1_all_H_randomForestN30.p']\n",
    "for pipeline_name in pipeline_names:\n",
    "    tokens = pipeline_name.split('_')\n",
    "    model_name = tokens[-1]\n",
    "    if model_name.endswith('.p'):\n",
    "        model_name = model_name[:-2]\n",
    "    features = '_'.join(tokens[:-1])\n",
    "    print(model_name, features)\n",
    "    predict(\"seq_seq1.fasta\", \"seq_seq1_numbered\", model_name, features)\n",
    "    sequence = 'VQLQESDAELVKPGASVKISCKASGYTFTDHVIHWVKQKPEQGLEWIGYISPGNGDIKYNEKFKGKATLTADKSSSTAYMQLNSLTSEDSAVYLCKRGYYVDYWGQGTTLTVSSAKTTPPSVYPLAPSMVTLGCLVKGYFPEPVTVTWNSGSLSSGVHTFPAVLQSDLYTLSSSVTVPSSTWPSETVTCNVAHPASSTKVDKKIE'\n",
    "    predict_single_sequence(\"roman_seq\", sequence, '', model_name, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b1313-4936-4877-8c8b-cf9773e22255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
