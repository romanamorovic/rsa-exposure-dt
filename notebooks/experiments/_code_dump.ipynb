{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a04e945-dc10-4696-9db8-d829a1d762a9",
   "metadata": {},
   "source": [
    "This code possibly to be utilized later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a49a1-6432-4da6-914a-98c1c4f02f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14bfc340-80a4-4cb1-b8e9-9b05430c57b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing new there, loading the data from the disk\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fasta_len</th>\n",
       "      <th>sasa_len</th>\n",
       "      <th>len_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2QTJ:H</th>\n",
       "      <td>475</td>\n",
       "      <td>400</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3CHN:H</th>\n",
       "      <td>475</td>\n",
       "      <td>133</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3CHN:L</th>\n",
       "      <td>214</td>\n",
       "      <td>66</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3CM9:H</th>\n",
       "      <td>462</td>\n",
       "      <td>144</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3CM9:L</th>\n",
       "      <td>214</td>\n",
       "      <td>61</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3HC4:L</th>\n",
       "      <td>213</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3M8O:H</th>\n",
       "      <td>221</td>\n",
       "      <td>219</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3QHZ:L</th>\n",
       "      <td>216</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4P3D:H</th>\n",
       "      <td>218</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5T5B:L</th>\n",
       "      <td>210</td>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6O3D:H</th>\n",
       "      <td>223</td>\n",
       "      <td>221</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6OTC:L</th>\n",
       "      <td>215</td>\n",
       "      <td>214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6PDR:H</th>\n",
       "      <td>213</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6Y1K:L</th>\n",
       "      <td>216</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7LM9:H</th>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7MTA:H</th>\n",
       "      <td>223</td>\n",
       "      <td>288</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7MTA:L</th>\n",
       "      <td>215</td>\n",
       "      <td>230</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7MTB:H</th>\n",
       "      <td>225</td>\n",
       "      <td>290</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7MTB:L</th>\n",
       "      <td>214</td>\n",
       "      <td>224</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fasta_len  sasa_len  len_diff\n",
       "2QTJ:H        475       400        75\n",
       "3CHN:H        475       133       342\n",
       "3CHN:L        214        66       148\n",
       "3CM9:H        462       144       318\n",
       "3CM9:L        214        61       153\n",
       "3HC4:L        213       212         1\n",
       "3M8O:H        221       219         2\n",
       "3QHZ:L        216       215         1\n",
       "4P3D:H        218       217         1\n",
       "5T5B:L        210       209         1\n",
       "6O3D:H        223       221         2\n",
       "6OTC:L        215       214         1\n",
       "6PDR:H        213       212         1\n",
       "6Y1K:L        216       215         1\n",
       "7LM9:H        226       225         1\n",
       "7MTA:H        223       288        65\n",
       "7MTA:L        215       230        15\n",
       "7MTB:H        225       290        65\n",
       "7MTB:L        214       224        10"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from fasta alignment\n",
    "import collections\n",
    "import utils\n",
    "\n",
    "deletes_number = 0\n",
    "\n",
    "dataframes = [\n",
    "    (fasta_unaligned_df,   '../../data/csv/fasta.csv'),\n",
    "    (fasta_unaligned_L_df,   '../../data/csv/fasta_L.csv'),\n",
    "    (fasta_unaligned_H_df,   '../../data/csv/fasta_H.csv'),\n",
    "    (sasa_unaligned_df,   '../../data/csv/sasa_merged_relative.csv'),\n",
    "    (fasta_aligned_L_df,   '../../data/csv/fasta_aho_L.csv'),\n",
    "    (fasta_aligned_H_df,   '../../data/csv/fasta_aho_H.csv'),\n",
    "    (fasta_aligned_df,   '../../data/csv/fasta_aho.csv'),\n",
    "]\n",
    "\n",
    "fasta_unaligned_lengths = utils.nondash_counts(fasta_unaligned_df)\n",
    "uneven_length_removals = collections.defaultdict(list)\n",
    "for sasa_index, sasa_row in sasa_unaligned_df.iterrows():\n",
    "    fasta_row = fasta_unaligned_df.loc[sasa_index]\n",
    "    \n",
    "    sasa_len = sasa_row.count()\n",
    "    fasta_len = fasta_unaligned_lengths[sasa_index]\n",
    "    len_diff = abs(sasa_len - fasta_len)\n",
    "    \n",
    "    if len_diff > 0:\n",
    "        deletes_number += 1\n",
    "        if deletes_number > 20: break\n",
    "        uneven_length_removals['index'].append(sasa_index)\n",
    "        uneven_length_removals['fasta_len'].append(fasta_len)\n",
    "        uneven_length_removals['sasa_len'].append(sasa_len)\n",
    "        uneven_length_removals['len_diff'].append(len_diff)\n",
    "        \n",
    "        # uncomment this block later\n",
    "        for df, path in dataframes:\n",
    "            df.drop(sasa_index, inplace=True, errors='ignore')\n",
    "\n",
    "for df, path in dataframes:\n",
    "    df.to_csv(path)\n",
    "\n",
    "\n",
    "uneven_length_removals_index = uneven_length_removals['index']\n",
    "if uneven_length_removals_index:\n",
    "    print('generating new removal data')\n",
    "    del uneven_length_removals['index']\n",
    "    uneven_length_removals_df = pd.DataFrame(uneven_length_removals, index=uneven_length_removals_index)\n",
    "    uneven_length_removals_df.to_csv('../../data/csv/uneven_length_removals.csv')\n",
    "else:\n",
    "    # This cell was executed already on this dataset\n",
    "    #   so the list of uneven lengths will be empty\n",
    "    # It is stored on the disk already, load it from there\n",
    "    print('nothing new there, loading the data from the disk')\n",
    "    uneven_length_removals_df = pd.read_csv('../../data/csv/uneven_length_removals.csv', index_col=0)\n",
    "\n",
    "uneven_length_removals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ef882-656e-462a-8371-c5e873a8d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove those sequences that do not have any cluster assigned\n",
    "keys_to_remove = X[~X['Id'].isin(clusters_df['sequence_id'])].index.to_list()\n",
    "X.drop(index=keys_to_remove, inplace=True)\n",
    "Y.drop(index=keys_to_remove, inplace=True)\n",
    "print(f'keys removed {keys_to_remove}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0767ef0-bc9c-415f-9e89-1f483a8deea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3801, 156), (435, 156), (3801, 156), (435, 156))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_keys = set(X['Id']).intersection(set(clustering_dataset_ids))\n",
    "test_keys = set(X['Id']).intersection(set(test_ids))\n",
    "X_train, X_test = X[X['Id'].isin(train_keys)], X[X['Id'].isin(test_keys)]\n",
    "Y_train, Y_test = Y[Y['Id'].isin(train_keys)], Y[Y['Id'].isin(test_keys)]\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce117c-365a-478d-8122-614404bc1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = pd.read_csv(CLUSTER_FILE, index_col='sequence_id').drop(columns='Unnamed: 0')\n",
    "clusters_df['Id'] = clusters_df.index\n",
    "clusters_df['cluster'] = clusters_df['cluster']\n",
    "X_train = pd.read_csv('../../data/csv/x_train.csv', index_col=0)\n",
    "Y_train = pd.read_csv('../../data/csv/y_train.csv', index_col=0)\n",
    "m = X_train.merge(clusters_df, on='Id', how='inner')\n",
    "groups = pd.Series(m['cluster'].values, index=m['Id'])\n",
    "\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b074d3ec-604a-492f-8d91-b650357f8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_miniset(X: pd.DataFrame, Y: pd.DataFrame, clust_order_start: int, clust_order_stop: int) -> tuple:\n",
    "    miniset_clusters = np.array(clusters_df['cluster'].value_counts()[clust_order_start:clust_order_stop].index)\n",
    "    miniset_ids = clusters_df[clusters_df['cluster'].isin(miniset_clusters)].index\n",
    "    miniset_ids = list(set(miniset_ids).intersection(set(X.index)))\n",
    "    Xm, Ym = X.loc[miniset_ids, :], Y.loc[miniset_ids, :]\n",
    "    return get_oh_matrix(Xm), Ym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d83bf-cd6e-45cb-bade-23fb1f5297bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def test_model(clf, input_params, xtr, ytr, xte, yte):    \n",
    "    pipeline, params, name = clf(input_params)\n",
    "    mor = MultiOutputRegressor(estimator=pipeline)\n",
    "    mor.fit(xtr, ytr)\n",
    "    predicts = mor.predict(xte)\n",
    "    \n",
    "    result_dev = utils.avg_deviation(yte, predicts)\n",
    "    print(f'{result_dev:.2f}%' , end='')\n",
    "    return result_dev, predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76b175-4a5d-43f3-98b9-eefeb8201d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(clf, Xmtr, Ymtr, Xmte, Ymte):\n",
    "    print(f'starting Xtrain: {Xmtr.shape} Xtest: {Xmte.shape}')\n",
    "    max_iter_values = [1, 5, 10, 20, 50, 100, 500, 1000, 5000]\n",
    "    for max_iter in max_iter_values:   \n",
    "        print(f'max_iter: {max_iter} - ', end='')\n",
    "        runtime = t.timeit(lambda: test_model(clf, max_iter, \n",
    "                                              Xmtr, Ymtr, Xmte, Ymte), number=1)\n",
    "        print(f' - {runtime:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef558a3-78b9-46ac-8571-368d582a6ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(n=-1):        \n",
    "    ppl = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        #('kernel_approx', Nystroem()),\n",
    "        ('svm', SVR(max_iter=n) if n>-1 else SVR())\n",
    "    ])\n",
    "    parameters = {\n",
    "        'estimator__svm__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'estimator__svm__max_iter': [1, 10, 50, 200, 500, 1000],\n",
    "        'estimator__svm__C' : np.logspace(0.01, 3, num=30),\n",
    "        'estimator__svm__degree' : [1, 3, 8],\n",
    "        'estimator__svm__coef0' : [0.01,10,0.5],\n",
    "        'estimator__svm__gamma' : ('auto','scale'),\n",
    "        #'estimator__kernel_approx__kernel': ['linear'],\n",
    "        #'estimator__kernel_approx__gamma': [1],\n",
    "        #'estimator__kernel_approx__n_components': [30],\n",
    "    }\n",
    "    return ppl, parameters, 'SVM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea6c8a5-b871-45d7-95f7-abc67333afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(svm, Xmtr, Ymtr, Xmte, Ymte)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8154c6b2-5e18-4571-9563-88e314c3645b",
   "metadata": {},
   "source": [
    "starting Xtrain: (474, 385) Xtest: (51, 385)\n",
    "max_iter: 1 - 15.54% - 1.97s\n",
    "max_iter: 5 - 14.02% - 2.10s\n",
    "max_iter: 10 - 13.26% - 2.19s\n",
    "max_iter: 20 - 11.96% - 2.44s\n",
    "max_iter: 50 - 11.33% - 3.07s\n",
    "max_iter: 100 - 11.07% - 3.88s\n",
    "max_iter: 500 - 10.89% - 6.44s\n",
    "max_iter: 1000 - 10.89% - 6.40s\n",
    "max_iter: 5000 - 10.89% - 6.39s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42f76912-78bc-4991-aa32-691715339e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_net(n=-1):\n",
    "    ppl = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('en', ElasticNet(max_iter=n) if n>-1 else ElasticNet())\n",
    "    ])\n",
    "    parameters = {\n",
    "        'estimator__en__alpha' : np.logspace(0.01, 3, num=30),\n",
    "        'estimator__en__positive': [True, False],\n",
    "        'estimator__en__tol': [0.0001, 0.001, 0.00001],\n",
    "        'estimator__en__max_iter': [1, 10, 50, 200, 500, 1000],\n",
    "    }\n",
    "    return ppl, parameters, 'ElasticNet'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "785b4a55-1696-4e9e-8163-bad4322d44ed",
   "metadata": {},
   "source": [
    "run(elastic_net, Xmtr, Ymtr, Xmte, Ymte)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afc0370c-2ea2-4252-8b99-6426407b0b2d",
   "metadata": {},
   "source": [
    "starting Xtrain: (474, 385) Xtest: (51, 385)\n",
    "max_iter: 1 - 9.84% - 2.29s\n",
    "max_iter: 5 - 8.25% - 2.37s\n",
    "max_iter: 10 - 8.05% - 2.41s\n",
    "max_iter: 20 - 7.76% - 2.52s\n",
    "max_iter: 50 - 7.72% - 2.77s\n",
    "max_iter: 100 - 7.72% - 3.28s\n",
    "max_iter: 500 - 7.71% - 5.24s\n",
    "max_iter: 1000 - 7.71% - 7.19s\n",
    "max_iter: 5000 - 7.71% - 16.87s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0bc1e298-91ae-46df-a57d-0395b9d2bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso(n=-1):\n",
    "    ppl = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lasso', Lasso(max_iter=n) if n>-1 else Lasso())\n",
    "    ])\n",
    "    parameters = {\n",
    "        'estimator__lasso__precompute': [True],\n",
    "        'estimator__lasso__alpha' : np.logspace(0.01, 3, num=30),\n",
    "        'estimator__lasso__positive': [True, False],\n",
    "        'estimator__lasso__tol': [0.0001, 0.001, 0.00001],\n",
    "        'estimator__lasso__max_iter': [1, 10, 50, 200, 500, 1000],\n",
    "    }\n",
    "    return ppl, parameters, 'Lasso'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1d7ec7d-a743-43db-996b-9afc85b8636d",
   "metadata": {},
   "source": [
    "run(lasso, Xmtr, Ymtr, Xmte, Ymte)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a3179dc-a01b-46ac-8e54-10eac63f15c8",
   "metadata": {},
   "source": [
    "starting Xtrain: (474, 385) Xtest: (51, 385)\n",
    "max_iter: 1 - 10.23% - 2.70s\n",
    "max_iter: 5 - 8.27% - 2.87s\n",
    "max_iter: 10 - 8.19% - 2.92s\n",
    "max_iter: 20 - 8.13% - 3.18s\n",
    "max_iter: 50 - 7.91% - 3.19s\n",
    "max_iter: 100 - 7.86% - 3.53s\n",
    "max_iter: 500 - 7.87% - 4.98s\n",
    "max_iter: 1000 - 7.87% - 6.09s\n",
    "max_iter: 5000 - 7.87% - 16.29s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79f65f5a-3df7-4e2f-804d-5b1ea92b0071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_ridge(n=-1):\n",
    "    ppl = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kr', KernelRidge())\n",
    "    ])\n",
    "    parameters = {\n",
    "        #'estimator__kr__kernel' : ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "        #'estimator__kr__alpha' : np.logspace(0.01, 3, num=30),\n",
    "        #'estimator__kr__degree' : [1, 2, 4, 8],\n",
    "        #'estimator__kr__coef0' : np.linspace(0.001, 50, num=10),\n",
    "        #'estimator__kr__gamma' : (1, 5, 10, 50, 100, 0.5),\n",
    "    }\n",
    "    return ppl, parameters, 'KernelRidge'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a306e29-0fd8-4e03-a0d1-2f29de171c4e",
   "metadata": {},
   "source": [
    "run(kernel_ridge, Xmtr, Ymtr, Xmte, Ymte)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "934fde5d-80b6-4f5f-b8c4-a61650cf1cd1",
   "metadata": {},
   "source": [
    "starting Xtrain: (474, 385) Xtest: (51, 385)\n",
    "max_iter: 1 - 32.54% - 4.78s\n",
    "max_iter: 5 - 32.54% - 4.85s\n",
    "max_iter: 10 - 32.54% - 4.90s\n",
    "max_iter: 20 - 32.54% - 5.10s\n",
    "max_iter: 50 - 32.54% - 5.15s\n",
    "max_iter: 100 - 32.54% - 5.04s\n",
    "max_iter: 500 - 32.54% - 5.05s\n",
    "max_iter: 1000 - 32.54% - 4.96s\n",
    "max_iter: 5000 - 32.54% - 4.93s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f791a63b-c022-443a-b724-c14e6b55e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(n=-1):\n",
    "    ppl = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('gbr', GradientBoostingRegressor(n_estimators=n) if n>-1 else GradientBoostingRegressor())\n",
    "    ])\n",
    "    parameters = {\n",
    "        'estimator__gbr__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "        'estimator__gbr__n_estimators': [1, 2, 5],\n",
    "        'estimator__gbr__criterion': ['friedman_mse', 'squared_error', 'mse', 'mae']\n",
    "    }\n",
    "    return ppl, parameters, 'GradientBoosting'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6363d2f4-832c-449c-ac85-78a31bd5af9b",
   "metadata": {},
   "source": [
    "run(gradient_boosting, Xmtr, Ymtr, Xmte, Ymte)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10359167-f4a3-4609-8bf0-4160d9fbc7b3",
   "metadata": {},
   "source": [
    "starting Xtrain: (474, 385) Xtest: (51, 385)\n",
    "max_iter: 1 - 11.79% - 2.31s\n",
    "max_iter: 5 - 10.06% - 3.45s\n",
    "max_iter: 10 - 8.87% - 4.86s\n",
    "max_iter: 20 - 8.14% - 7.50s\n",
    "max_iter: 50 - 8.34% - 15.88s\n",
    "max_iter: 100 - 8.87% - 31.62s\n",
    "max_iter: 500 - 9.91% - 146.13s\n",
    "max_iter: 1000 - 10.17% - 291.84s\n",
    "max_iter: 5000 - 10.66% - 1424.92s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6932e6-dfed-4853-b7a3-8ce81b500137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO complete the list\n",
    "models = [svm, elastic_net, lasso, gradient_boosting]\n",
    "loss_function = make_scorer(utils.avg_deviation, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c50862d7-f62c-47a0-bda0-6ee401976a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "#for model in tqdm(models, total=len(models)):\n",
    "#for model in models:\n",
    "\n",
    "logger.info(model)\n",
    "pipeline, params, name = model()\n",
    "mor = MultiOutputRegressor(estimator=pipeline)\n",
    "\n",
    "splitter = LeaveOneGroupOut()\n",
    "split = splitter.split(Xmtr, Ymtr, groups=groups)\n",
    "#grid = RandomizedSearchCV(mor, {}, verbose=0, \n",
    "#                          n_iter=1, n_jobs=-1, scoring=loss_function, cv=split)\n",
    "scores = cross_validate(pipeline, Xmtr, Ymtr, cv=split, groups=groups, \n",
    "                        scoring=loss_function, return_train_score=True, n_jobs=-1,\n",
    "                        cv=tqdm(split, total=groups.nunique()))\n",
    "#grid.fit(Xmtr, Ymtr)\n",
    "#estimator = grid.best_estimator_\n",
    "#best_params = grid.best_params_\n",
    "#Y_pred = estimator.predict(Xmte)\n",
    "#results[name] = Y_pred.mean()\n",
    "#results[name + '_params'] = best_params\n",
    "results[name] = scores\n",
    "print(f'model {name} score {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972599c-7020-49e1-9ae4-f5c23fc6f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results\n",
    "with open(OUTPUT_FILE, 'wb') as o:\n",
    "    pickle.dump(results, o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39a2b13-f52f-4153-ab62-d9662cb7d72c",
   "metadata": {},
   "source": [
    "## 03_ogo_cont_windows.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9784eaa-d606-4ed7-a753-a4063726d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_training(window_start = 0):\n",
    "    columns = X.columns[window_start: window_start+WINDOW_LEN]\n",
    "\n",
    "    X_window = X[columns]\n",
    "    Y_window = Y[columns[0]].to_frame()\n",
    "    X_window = utils.get_oh_matrix(X_window)\n",
    "    X_window = utils.remove_useless_columns(X_window)\n",
    "    #X_window['window_start'] = window_start\n",
    "    \n",
    "    if window_start == 0:\n",
    "        logger.info(f'pos {window_start} compressed shape {X_window.shape}')\n",
    "        logged = True\n",
    "\n",
    "    split = LeaveOneGroupOut().split(X_window, Y_window, groups=groups)\n",
    "    scores = cross_validate(model, X_window, Y_window, \n",
    "                            groups=groups,\n",
    "                            n_jobs=N_JOBS, \n",
    "                            scoring=loss, \n",
    "                            verbose=VERBOSE, cv=split,\n",
    "                            return_train_score=True, \n",
    "                            error_score=ERROR_SCORE)\n",
    "    \n",
    "    return generate_results(scores, window_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ae9d4-2e44-4246-8af9-04b3cb756c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:papermill:pos 0 compressed shape (3801, 87)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............., score=(train=-34.544, test=-22.702) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.178, test=-33.647) total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............., score=(train=-33.540, test=-28.852) total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............., score=(train=-33.574, test=-34.175) total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..............., score=(train=-33.564, test=-38.710) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.491, test=-37.791) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.628, test=-12.919) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.602, test=-15.691) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.610, test=-30.360) total time=   0.7s\n",
      "[CV] END ................, score=(train=-33.569, test=-1.730) total time=   0.8s\n",
      "[CV] END ..............., score=(train=-33.617, test=-11.461) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.592, test=-44.451) total time=   0.7s\n",
      "[CV] END ................, score=(train=-33.614, test=-9.368) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.620, test=-6.350) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.630, test=-6.050) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.592, test=-42.197) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.641, test=-18.424) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.609, test=-10.859) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.569, test=-1.492) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.558, test=-32.836) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.615, test=-4.226) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.625, test=-8.605) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.608, test=-31.033) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.613, test=-11.086) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.639, test=-6.424) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.580, test=-44.410) total time=   0.7s\n",
      "[CV] END ..............., score=(train=-33.607, test=-13.179) total time=   0.5s\n",
      "[CV] END ..............., score=(train=-33.607, test=-12.344) total time=   0.7s\n",
      "[CV] END ..............., score=(train=-33.591, test=-34.876) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.607, test=-9.111) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-2.376) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.609, test=-10.488) total time=   0.7s\n",
      "[CV] END ..............., score=(train=-33.617, test=-12.854) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.608, test=-21.748) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.614, test=-2.650) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.538, test=-30.605) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-3.279) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.559, test=-30.524) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.596, test=-39.253) total time=   0.7s\n",
      "[CV] END ................, score=(train=-33.613, test=-8.450) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.521, test=-19.487) total time=   0.7s\n",
      "[CV] END ..............., score=(train=-33.557, test=-33.759) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.611, test=-28.429) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.614, test=-0.500) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.552, test=-2.769) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.614, test=-8.462) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.588, test=-48.250) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.608, test=-3.605) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.608, test=-2.523) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.604, test=-15.045) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-7.932) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.604, test=-20.098) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-8.363) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.621, test=-12.549) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-1.557) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.608, test=-3.428) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.608, test=-4.850) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.607, test=-4.560) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-2.764) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-2.916) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.606, test=-9.714) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.574, test=-49.397) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.598, test=-36.417) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.586, test=-50.706) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-1.596) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-0.228) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-1.596) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-9.227) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-0.638) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-0.333) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.614, test=-15.658) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.604, test=-21.343) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-0.333) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.604, test=-15.117) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.607, test=-19.085) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.614, test=-5.914) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.552, test=-2.629) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-7.865) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-0.911) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.615, test=-13.172) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-1.493) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.615, test=-33.889) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.552, test=-0.907) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.569, test=-2.304) total time=   0.7s\n",
      "[CV] END ................, score=(train=-33.630, test=-4.659) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.603, test=-17.281) total time=   0.7s\n",
      "[CV] END ..............., score=(train=-33.603, test=-18.572) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-6.024) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-0.595) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.569, test=-2.067) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-3.535) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.607, test=-7.614) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-1.572) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.607, test=-10.083) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.608, test=-15.067) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.608, test=-7.943) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.603, test=-18.651) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.608, test=-7.542) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.604, test=-18.525) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.605, test=-26.874) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-4.419) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.602, test=-13.891) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.608, test=-8.043) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.608, test=-12.155) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-0.333) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-1.557) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-1.261) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-0.232) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.608, test=-5.039) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-1.493) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-0.436) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.585, test=-2.747) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-1.493) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.607, test=-7.279) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-0.807) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.606, test=-3.460) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-3.843) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.605, test=-1.491) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.607, test=-15.103) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-1.000) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.603, test=-14.819) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-1.000) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.602, test=-11.613) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.607, test=-12.149) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-1.557) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-2.490) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.608, test=-9.527) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-0.780) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-2.910) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.608, test=-5.551) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-3.929) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-3.135) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-6.909) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.586, test=-2.459) total time=   0.6s\n",
      "[CV] END ..............., score=(train=-33.606, test=-50.705) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.608, test=-6.016) total time=   0.6s\n",
      "[CV] END ................, score=(train=-33.609, test=-4.756) total time=   0.6s\n"
     ]
    }
   ],
   "source": [
    "limit = X.shape[1]-WINDOW_LEN\n",
    "#limit = 2\n",
    "\n",
    "partial_results = []\n",
    "for i in range(limit):\n",
    "    partial_results.append(do_training(window_start=i))\n",
    "\n",
    "res_df = pd.concat(partial_results, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
